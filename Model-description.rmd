---
title: "Experimental Information Diffusion Model"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(here)
library(ggplot2)
library(gganimate)
library(reshape2)
library(viridis)
source(here('diffusion_with_new_innovation.R'))
source(here("graph_networks.R"))
source(here("init_info.R"))

```
## Basic Components
### Information/Trait to Diffuse
#### Type-Level Attributes

  - Engagement Score: Measures how engaging the type of information is(for example it could be seen as a measure of likes, shares, comments this type of info could get)
  - Decay Rate: Determines how quickly the novelty of items in this type decays over time.
  
#### Item-Level Attributes
  - Attractiveness: Represents how appealing the information is (correlated within a type based on a random probability)
  - Popularity: The current level of engagement .
  - Novelty: A dynamic attribute that decreases over time according to the decay rate of the information type.
Agents

#### Network Structure

   - N number of gents are connected through a small-world network.

#### Initialization

  - Each agent is initialized with a set of repertoires containing random items.

#### Learning Mechanism

  - Agents learn features of information attributes (attractiveness, popularity, novelty) and social attributes (social influence).
  - RL Social Feature Learning Model
      - choosing information items either from their repertoires or observations from connected neighbours
      - Q-Values: Agents estimate the value of actions based on learned weights for item attributes and social influence.
      
#### Distance based Similarity Calculation
  - If two items have similar type they are assigned a score of 1
  - If not a simple distance (d) is calculated between the type level attribures - abs(a1 - b1)
  - This distance is then convereted to similarity score: 1 / 1 - d 
  
  ```{r, eval = FALSE}
  calculate_similarity <- function(type1, type2, type_attributes) {
    if (type1 == type2) {
        return(1) #types are the same therefore max similarity score
    } else {
        engagement_diff <- abs(type_attributes$Engagement[type1] - type_attributes$Engagement[type2])
        decay_diff <- abs(type_attributes$DecayRate[type1] - type_attributes$DecayRate[type2])
        similarity_score <- 1 / (1 + engagement_diff + decay_diff) #convert distance to similarity score
        return(similarity_score)
    }
}
  ```

#### Perceived Reward Calculation(Experimental - commented out included in current implementation)

  - Intrinsic Value: Sum of item-level attributes (attractiveness, popularity, novelty).
  - Social Influence Value: Influence from observing other agents' choices.
  - Personal Bias: Based on the similarity of the item's type to the majority type in the agent's repertoire.
Similarity Calculation

Type Similarity: Calculated using a function that considers engagement score and decay rate differences between types.

## Code Description
### Diffusion Model
First Initialize dataframes for attribute weights (for ease of adding new items to the weight matrix, social weight is handeled in a different matrix.) Agents are also initialized with random set of info items in their `repertoires`

```{r, eval = FALSE}
Info_diffusion_SFL <- function(N, alpha, beta_mu, beta_sd, graph, original_info_df, type_attributes, timesteps = 40, social_influence = TRUE, new_info_prob = 0.01) {
    info_df <- normalize_info_attributes(original_info_df)  # Start with a normalized version of the original info_df
    num_info <- nrow(info_df)
    num_attributes <- ncol(info_df) - 1  # Exclude ID column
    # print(num_info)
    # print(num_attributes)
    agent_betas <- pmax(rnorm(N, beta_mu, beta_sd), 0)
    attribute_weights <- matrix(0, nrow = N, ncol = (num_info * num_attributes))  # +1 for type similarity
    social_weights <- if (social_influence) rep(0, N) else NULL
    social_value <- matrix(0, nrow = N, ncol = num_info)
    # print(ncol(attribute_weights))
    output <- data.frame(
        trial = rep(1:timesteps, each = N),
        agent = rep(1:N, timesteps),
        repertoires = I(replicate(N * timesteps, list())),
        last_choice = I(replicate(N * timesteps, list())),
        reward = rep(NA, timesteps * N),
        social_weights = rep(NA, timesteps * N)
    )
    

    # Initialize agents with a random repertoire (preferences)
    agent_repertoires <- lapply(1:N, function(i) sample(num_info, sample(1:3, 1)))

    for (i in 1:N) {
        output$repertoires[i] <- list(agent_repertoires[[i]])
        output$last_choice[i] <- output$repertoires[i]
    }
```

Then, at each timestep, with some randomly defined probability(new_info_prob), a new information item is added to the simulation. This new item is appended to the original and normalized information data frames. The attributes and weights are updated accordingly to accommodate the new item. A random agent is seeded with this new information item in their repertoire.

```{r, eval = FALSE}
for (t in 1:timesteps) {
        if (runif(1) < new_info_prob && t < 100) {
            # print(t)
            new_info_df <- add_new_information(original_info_df, 1, type_attributes)
            original_info_df <- rbind(original_info_df, new_info_df)

            new_info_df <- normalize_info_attributes(new_info_df)
            info_df <- rbind(info_df, new_info_df)
            num_info <- nrow(info_df)
            new_columns_needed <- num_attributes
            attribute_weights <- cbind(attribute_weights, matrix(0, nrow = N, ncol = new_columns_needed))

            additional_cols <- num_info - ncol(social_value)
            if (additional_cols > 0) {
                social_value <- cbind(social_value, matrix(0, nrow = N, ncol = additional_cols))
            }
            # print(info_df)
            new_item_index <- num_info
            seed_agent_index <- sample(1:N, 1)
            agent_repertoires[[seed_agent_index]] <- c(agent_repertoires[[seed_agent_index]], new_item_index)
        }
```

Then, For each agent in each timestep, if social influence is TRUE it identifies the neighbors of the agent in the social network and gathers the unique items observed by these neighbors for choice considerations. 

Last choices made by these neighbors from the previous timestep are collected. Then the frequency of these choices is calculated and normalized to derive the social influence values , which are then stored in the social_value matrix.

```{r, eval = FALSE}
for (i in 1:N) {
            idx <- (t - 1) * N + i
            if (social_influence) {
                neighs_ids <- neighbors(graph, i)
                observed_items <- unique(unlist(agent_repertoires[neighs_ids]))

                if (length(neighs_ids) > 0 && t > 1) {
                    neigh_last_choices <- unlist(lapply(neighs_ids, function(nid) {
                        return(output$last_choice[(t - 2) * N + nid][[1]])
                    }))

                    if (length(neigh_last_choices) > 0) {
                        choice_counts <- table(factor(neigh_last_choices, levels = 1:num_info))
                        full_choice_counts <- as.numeric(choice_counts)
                        social_value[i, ] <- full_choice_counts / length(neigh_last_choices)
                    }
                }
            }
```

#### Q-Value Calculation

- Q_values of zeros is created, with one element for each information item

- combine the items in the agent's repertoire and observed items (from neighbours) into available_items.

- Q_value calculation
  - For each available item:
    - Compute the start and end indices for its attribute weights.
Check for index out-of-bounds errors.
    - Calculate type similarity between the item's type and the majority type in the agent's repertoire.
    - Gather the item's attributes (Attractiveness, Popularity, Novelty) and type similarity into features.
    - Calculate the Q-value as the weighted sum of features. Include social value if social influence is enabled.
    
  
```{r, eval = FALSE}
            Q_values <- numeric(num_info)
            available_items <- unique(c(agent_repertoires[[i]], if (social_influence) observed_items else NULL))

            for (j in available_items) {
                start_index <- (j - 1) * num_attributes + 1
                end_index <- start_index + num_attributes - 1
                # print(start_index)
                # print(end_index)

                if (end_index > ncol(attribute_weights)) {
                    stop("Index out of bounds: end_index exceeds the number of columns in attribute_weights")
                }

                maj_type <- majority_type(agent_repertoires[[i]], info_df)
                type_similarity <- calculate_similarity(info_df$Type[j], maj_type, type_attributes)
                info_attributes <- c(info_df$Attractiveness[j], info_df$Popularity[j], info_df$Novelty[j], type_similarity)
                features <- info_attributes

                
                # type_similarity_weight_index <- ncol(attribute_weights)  # last column for type similarity
                # print(length(features))
                if (length(features) != (end_index - start_index + 1)) {
                    stop("Mismatch in lengths of features and attribute_weights indices")
                }

                if (social_influence) {
                    Q_values[j] <- sum(attribute_weights[i, start_index:end_index] * features) + social_weights[i] * social_value[i, j]
                } else {
                    Q_values[j] <- sum(attribute_weights[i, start_index:end_index] * features) 
                }
            }

```

After the Q-value calculations of the items the agent has access to, in order to make a choice:
  - set invalid indices (non-available items) to -Inf to effectively zero out their probability
  - apply softmax function
  - make a choice
  - reward fuction not updated in this case
  - update the attribute weights based on the reward
  - add the chosen item to the agent's repertoire ensuring uniqueness.

```{r, eval = FALSE}
            valid_indices <- available_items
            invalid_indices <- setdiff(1:num_info, valid_indices)
            Q_values[invalid_indices] <- -Inf  # Effectively zero out the probability
            print(Q_values)
            exp_values <- exp(agent_betas[i] * Q_values)
            probabilities <- exp_values / sum(exp_values)

            probabilities[probabilities < 0] <- 0

            if (any(is.na(probabilities)) || any(is.infinite(probabilities))) {
                probabilities[is.na(probabilities) | is.infinite(probabilities)] <- 0
            }

            if (sum(probabilities) == 0) {
                probabilities <- rep(1, length(probabilities))
            }
            probabilities <- probabilities / sum(probabilities)

            choice <- sample(1:num_info, 1, prob = probabilities)
            output$last_choice[idx] <- list(choice)
            reward <- rnorm(1, mean = info_df$Attractiveness[choice]^2, sd = 0.1)
            # reward <- calculate_perceived_reward(info_df, choice, agent_repertoires, i, type_attributes, social_value, social_influence, attribute_weights)
            # print(reward)
            output$reward[idx] <- reward

            actual_reward <- reward
            Q_adopt <- Q_values[choice]
            delta <- actual_reward - Q_adopt
            # print(choice)
            
            chosen_start_index <- (choice - 1) * num_attributes + 1
            chosen_end_index <- chosen_start_index + (num_attributes - 1)
            # print(chosen_start_index);print(chosen_end_index)
            attribute_weights[i, chosen_start_index:chosen_end_index] <- attribute_weights[i, chosen_start_index:chosen_end_index] + alpha * delta * info_attributes
            # print(attribute_weights[i, chosen_start_index:chosen_end_index])
            if (social_influence) {
                social_weights[i] <- social_weights[i] + alpha * delta * social_value[i, choice]
                output$social_weights[idx] <- social_weights[i]
            }

            agent_repertoires[[i]] <- unique(c(agent_repertoires[[i]], choice))

```

At last, compute frequency of each information item and update the popularity, and adjust the Novelity according to the decay rate of the type as well.

```{r, eval = FALSE}
        popularity_counts <- rep(0, num_info)
        for (i in 1:N) {
            idx <- (t - 1) * N + i
            last_choice <- output$last_choice[idx][[1]]
            popularity_counts[last_choice] <- popularity_counts[last_choice] + 1
        }
        popularity <- popularity_counts / N
        info_df$Popularity <- popularity

        for (i in 1:nrow(info_df)) {
            type <- info_df$Type[i]
            decay_rate <- type_attributes$DecayRate[type]
            info_df$Novelty[i] <- pmax(info_df$Novelty[i] - decay_rate, 0)

```

### Creating Information items 

At the start, to initialize the agents with, a number of information items are created, with a specified number of types. 
The function assigns random types to each item and initializes their attractiveness, popularity, and novelty attributes randomly drawn from a distribution with lower and upper bounds. The attributes for each item are probabilistically varied based on a base value for their type, ensuring that items of the same type have some level of similarity. The function returns a data frame containing these information items and their attributes

```{r, eval = FALSE}
initialize_information <- function(num_info, type_attributes, mean_attractiveness = 5, sd_attractiveness = 1.5,
                                   mean_popularity = 5, sd_popularity = 1.5, mean_novelty = 5, sd_novelty = 1.5,
                                   lower_bound_attractiveness = 0, upper_bound_attractiveness = 10,
                                   lower_bound_popularity = 1, upper_bound_popularity = 10,
                                   lower_bound_novelty = 0, upper_bound_novelty = 10) {

    '
    Initialize information items with attributes based on types
    args:
        num_info: number of information items
        num_types: number of types of information
    returns:
        info_df: data frame with information items and attributes
    '
    num_types <- nrow(type_attributes)

    # assign types as numeric values
    types <- sample(1:num_types, num_info, replace = TRUE)

    info_df <- data.frame(
        ID = 1:num_info,
        Type = as.factor(types),
        Attractiveness = numeric(num_info),
        Popularity = numeric(num_info),
        Novelty = numeric(num_info) 
    )

    # assign attributes to informations based on type with probabilistic variation
    for (t in 1:num_types) {
        # get indices of items with type t
        indices <- which(info_df$Type == t)
        base_attractiveness <- rtruncnorm(1, a = lower_bound_attractiveness, b = upper_bound_attractiveness,
                                          mean = mean_attractiveness, sd = sd_attractiveness)
        base_popularity <- round(rnorm(1, mean = mean_popularity, sd = sd_popularity))
        base_popularity <- pmax(pmin(base_popularity, upper_bound_popularity), lower_bound_popularity)

       #base_novelty <- rtruncnorm(1, a = lower_bound_novelty, b = upper_bound_novelty,
         #                         mean = mean_novelty, sd = sd_novelty)

        # probablity of being simmilar to the base within the type with minimum 40% chance
        prob_similar = runif(1, 0.4, 0.8)  

        for (i in indices) {
        
            #novelity is drawn randomly from a truncated normal distribution for each item
            info_df$Novelty[i] <- rtruncnorm(1, a = lower_bound_novelty, b = upper_bound_novelty,
                                             mean = mean_novelty, sd = sd_novelty)
            if (runif(1) < prob_similar) {
                # attributes are similar to the base with some variation
                info_df$Attractiveness[i] <- base_attractiveness + rnorm(1, mean = 0, sd = 0.5)
                info_df$Popularity[i] <- round(base_popularity + rnorm(1, mean = 0, sd = 5))
                info_df$Popularity[i] <- pmax(pmin(info_df$Popularity[i], upper_bound_popularity), lower_bound_popularity)
            } else {

                # attributes are drawn randomly from a normal distribution
                info_df$Attractiveness[i] <- rtruncnorm(1, a = lower_bound_attractiveness, b = upper_bound_attractiveness,
                                                        mean = mean_attractiveness, sd = sd_attractiveness)
                info_df$Popularity[i] <- round(rnorm(1, mean = mean_popularity, sd = sd_popularity))
                info_df$Popularity[i] <- pmax(pmin(info_df$Popularity[i], upper_bound_popularity), lower_bound_popularity)
            }
        }
    }

    # normalize item-level attributes
    # info_df <- normalize_info_attributes(info_df)
    return(info_df)
}


```

The `add_new_information` function adds new information items to an existing data frame. Each new item is assigned a type and given attributes for attractiveness, popularity, and novelty. The attractiveness of new items may be based on existing items of the same type with a some random probability, adding some variation. Returns a data frame containing the new information items.

```{r, eval = FALSE}
add_new_information <- function(info_df, num_new_info, type_attributes, mean_attractiveness = 5, sd_attractiveness = 1.5,
                                lower_bound_attractiveness = 0, upper_bound_attractiveness = 10,
                                lower_bound_popularity = 1, upper_bound_popularity = 10,
                                lower_bound_novelty = 0, upper_bound_novelty = 10,
                                prob_base_on_existing = 0.7) {  #with probablity of basing attractiveness on existing items

    new_ids <- (max(info_df$ID) + 1):(max(info_df$ID) + num_new_info)
    new_types <- sample(1:nrow(type_attributes), num_new_info, replace = TRUE)

    new_info_df <- data.frame(
        ID = new_ids,
        Type = as.factor(new_types),
        Attractiveness = numeric(num_new_info),
        Popularity = rep(lower_bound_popularity, num_new_info),
        Novelty = rep(upper_bound_novelty, num_new_info)
    )

    for (i in 1:num_new_info) {
        current_type <- new_types[i]
        existing_items <- info_df[info_df$Type == current_type, ]
        
        if (nrow(existing_items) > 0 && runif(1) < prob_base_on_existing) {
            # base attractiveness on an existing item with some variation
            base_item <- existing_items[sample(nrow(existing_items), 1), ]
            new_info_df$Attractiveness[i] <- base_item$Attractiveness + rnorm(1, mean = 0, sd = sd_attractiveness / 2)
        } else {
            #assign random attractiveness
            new_info_df$Attractiveness[i] <- rtruncnorm(1, a = lower_bound_attractiveness, b = upper_bound_attractiveness, 
                                                        mean = mean_attractiveness, sd = sd_attractiveness)
        }
    }

    return(new_info_df)
}

```
## Some Plots



```{r, echo=FALSE}

# Parameters
N <- 50
alpha <- 0.1
beta_mu <- 5
beta_sd <- 0.1
timesteps <- 300


k <- 5
g <- create_small_world_network(N = N, k, 0.1)
set.seed(1)
# info_df <- initialize_information(num_info = 3, num_types = 2)
type_attrib <- initialize_type_attributes(num_types = 2)
print('Randomly created info types with attributes')
print(type_attrib)
info_df <- initialize_information(num_info = 3, type_attributes = type_attrib)
social_influence <- TRUE

result <- Info_diffusion_SFL(N, alpha, beta_mu, beta_sd, g, info_df, type_attrib, timesteps, social_influence, 0.05)
output <- result$output
info_df <- result$info_df
print('Final Information items dataframe with attributes')
print(info_df)

```

```{r, echo=FALSE, fig.width=12, fig.height=6}
# Extract adoption data
adoption_matrix <- matrix(0, nrow = timesteps, ncol = nrow(info_df))
for (t in 1:timesteps) {
    for (i in 1:N) {
        idx <- (t - 1) * N + i
        choice <- output$last_choice[[idx]]
        adoption_matrix[t, choice] <- adoption_matrix[t, choice] + 1
    }
}
options(repr.plot.width = 24, repr.plot.height = 10)

adoption_df <- as.data.frame(adoption_matrix)
adoption_df$Timestep <- 1:timesteps
adoption_melt <- melt(adoption_df, id.vars = "Timestep", variable.name = "Info_ID", value.name = "Adoptions")

ggplot(adoption_melt, aes(x = Timestep, y = Adoptions, color = Info_ID)) +
    geom_line() +
    labs(title = "Adoption Rate of Information Items Over Time", x = "Timestep", y = "Number of Adoptions", color = "Info ID") +
    theme_minimal()

```

```{r, echo=FALSE, fig.width=12, fig.height=6}
# Extract the preferences from finaldf and reshape for plotting
finaldf <- result$output
preferences_matrix <- matrix(NA, nrow = timesteps, ncol = N)
for (t in 1:timesteps) {
    for (i in 1:N) {
        idx <- (t - 1) * N + i
        choice <- unlist(finaldf$last_choice[[idx]])
        preferences_matrix[t, i] <- ifelse(length(choice) > 0, choice[length(choice)], NA)
    }
}

# Convert the preferences matrix to a data frame suitable for ggplot2
preferences_df <- as.data.frame(preferences_matrix)
preferences_df$Timestep <- 1:timesteps
preferences_melt <- reshape2::melt(preferences_df, id.vars = "Timestep", variable.name = "Agent", value.name = "Info_ID")

# Ensure Info_ID is a factor with correct levels
preferences_melt$Info_ID <- factor(preferences_melt$Info_ID)
options(repr.plot.width = 24, repr.plot.height = 18)

# Plot the heatmap of preferences over time
ggplot(preferences_melt, aes(x = Agent, y = Timestep, fill = Info_ID)) +
    geom_tile() +
    scale_fill_viridis_d(na.value = "white") +
    labs(title = "Heatmap of Preferences Over Time", x = "Agent", y = "Timestep", fill = "Info ID") +
    theme_minimal()

```

```{r, echo=FALSE, fig.width=12, fig.height=6}
social_weights <- result$output$social_weights

expected_length <- timesteps * N
actual_length <- length(social_weights)

if (actual_length == expected_length) {
    social_weights_df <- data.frame(
        Timestep = rep(1:timesteps, each = N),
        Agent = rep(1:N, times = timesteps),
        Social_Weight = social_weights
    )

    avg_social_weights_over_time <- aggregate(Social_Weight ~ Timestep, data = social_weights_df, mean)

    plot_data <- data.frame(
        Timestep = avg_social_weights_over_time$Timestep,
        Avg_Social_Weight = avg_social_weights_over_time$Social_Weight
    )

    ggplot(plot_data, aes(x = Timestep, y = Avg_Social_Weight), size = 5) +
        geom_line(color = "blue") +
        labs(title = "change in social influence weight", x = "Timestep", y = "average social weight") +
        theme_minimal()
} else {
    print("Error: The length of social_weights does not match the expected length.")
}

```